{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projet : Implémentation un modèle de scoring (Data Preprocessing)\n",
    "\n",
    "### Partie 2 : Data Cleaning and Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classic.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data Viz.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing.\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "\n",
    "# Import custom functions.\n",
    "from Utils.utils_preprocessing import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format & option.\n",
    "sns.set(rc={'figure.figsize':(16,9)})\n",
    "pd.options.display.max_columns = 100\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
    "\n",
    "# Style use.\n",
    "sns.set_style('darkgrid')\n",
    "\n",
    "# Filter warnings.\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data.\n",
    "df_app_train = pd.read_csv(\"Data/application_train.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Cleaning and Preprocessing\n",
    "\n",
    "- Delete observation with not enough information\n",
    "- Filter outliers\n",
    "- Delete categorical features with not enough information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling of the majority class.\n",
    "df_app_train['Nbr_nan'] = df_app_train[df_app_train['TARGET']==0].isna().sum(axis=1)\n",
    "df_app_train = df_app_train[(df_app_train[\"Nbr_nan\"] < 48) | (df_app_train[\"Nbr_nan\"] != np.nan)]\n",
    "del df_app_train['Nbr_nan'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace outliers and anomaly by NaN\n",
    "df_app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace = True)\n",
    "\n",
    "# Filter anomaly.\n",
    "df_app_train = df_app_train[df_app_train['CODE_GENDER'] != 'XNA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your selected dataframe has 122 columns.\n",
      "There are 68 columns that have missing values.\n"
     ]
    }
   ],
   "source": [
    "# Check missing values on features.\n",
    "df_missing_values = missing_values_table(df_app_train)\n",
    "\n",
    "# Check on categorical features.\n",
    "# Delete 1 feature with too many missing values.\n",
    "df_missing_values[df_missing_values.Feature_type == object]\n",
    "del df_app_train[\"FONDKAPREMONT_MODE\"]\n",
    "\n",
    "# Check on numerical features.\n",
    "# Delete 1 feature with too many missing values.\n",
    "df_missing_values[df_missing_values.Feature_type == 'float64']\n",
    "del df_app_train[\"OWN_CAR_AGE\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple ratio features.\n",
    "df_app_train['DAYS_EMPLOYED_PERC'] = df_app_train['DAYS_EMPLOYED'] / df_app_train['DAYS_BIRTH']\n",
    "df_app_train['INCOME_CREDIT_PERC'] = df_app_train['AMT_INCOME_TOTAL'] / df_app_train['AMT_CREDIT']\n",
    "df_app_train['INCOME_PER_PERSON'] = df_app_train['AMT_INCOME_TOTAL'] / df_app_train['CNT_FAM_MEMBERS']\n",
    "df_app_train['ANNUITY_INCOME_PERC'] = df_app_train['AMT_ANNUITY'] / df_app_train['AMT_INCOME_TOTAL']\n",
    "df_app_train['PAYMENT_RATE'] = df_app_train['AMT_ANNUITY'] / df_app_train['AMT_CREDIT']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Preprocessing for numerical and categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in training and testing set.\n",
    "X, y = df_app_train.iloc[:, df_app_train.columns != \"TARGET\"], df_app_train.TARGET\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# Store id_clients.\n",
    "id_clients_train = X_train[\"SK_ID_CURR\"]\n",
    "id_clients_test = X_test[\"SK_ID_CURR\"]\n",
    "\n",
    "# Deleted id_clients before preprocessing.\n",
    "del X_train[\"SK_ID_CURR\"]\n",
    "del X_test[\"SK_ID_CURR\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical Features\n",
    "\n",
    "- **Iterative imputer :** Chaque variable avec valeur manquante est modélisée comme un **y** dont on estime la valeur par les valeurs des **n_nearest_feature** de celle-ci. A chaque étape, une feature est désignée comme une **cible y** et les autres colonnes de caractéristiques sont traitées comme des entrées X. Un modèle de regression est ajusté sur (X, y) pour les y connus\n",
    "\n",
    "- **Rescaling :**  \n",
    "-> impact sur la descente de gradient  \n",
    "-> Nécessaire lorqu'il y a un calcul de vecteur de poids, d'une distance ou d'un clustering  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation on continuous features.\n",
    "X_train_num, X_test_num = X_train.select_dtypes(exclude=[\"object\"]), X_test.select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "# Imputation.\n",
    "impute = IterativeImputer(n_nearest_features=15, imputation_order='ascending', random_state=42)\n",
    "X_train_num = pd.DataFrame(impute.fit_transform(X_train_num), columns=X_train_num.columns)\n",
    "X_test_num = pd.DataFrame(impute.transform(X_test_num), columns=X_test_num.columns)\n",
    "\n",
    "# Rescaling with MinMaxScaler.\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train_num = pd.DataFrame(scaler.fit_transform(X_train_num), columns=X_train_num.columns)\n",
    "X_test_num = pd.DataFrame(scaler.transform(X_test_num), columns=X_train_num.columns)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical Features\n",
    "\n",
    "- **Imputation :** Simple_imputer avec comme stratégie : + fréquente\n",
    "- **Encoding :** Encoding via Target Encoding pour limiter le fléau de la dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding and imputation on categorical features.\n",
    "X_train_categ, X_test_categ = impute_cat_feature(X_train[[\"OCCUPATION_TYPE\", \"ORGANIZATION_TYPE\", \"NAME_INCOME_TYPE\", \"NAME_EDUCATION_TYPE\", \"CODE_GENDER\"]],\n",
    "                                                 X_test[[\"OCCUPATION_TYPE\", \"ORGANIZATION_TYPE\", \"NAME_INCOME_TYPE\", \"NAME_EDUCATION_TYPE\", \"CODE_GENDER\"]], \n",
    "                                                 y_train, \n",
    "                                                 encoder=\"TargetEncoder\")\n",
    "X_train_categ.dropna(inplace=True, axis=1)\n",
    "X_test_categ.dropna(inplace=True, axis=1)\n",
    " \n",
    "# Keep columns name.\n",
    "X_train_categ.columns = [\"OCCUPATION_TYPE\", \"ORGANIZATION_TYPE\", \"NAME_INCOME_TYPE\", \"NAME_EDUCATION_TYPE\", \"CODE_GENDER\"]\n",
    "X_test_categ.columns = [\"OCCUPATION_TYPE\", \"ORGANIZATION_TYPE\", \"NAME_INCOME_TYPE\", \"NAME_EDUCATION_TYPE\", \"CODE_GENDER\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset indexes.\n",
    "X_train_num.reset_index(inplace=True, drop=True)\n",
    "X_train_categ.reset_index(inplace=True, drop=True)\n",
    "X_test_num.reset_index(inplace=True, drop=True)\n",
    "X_test_categ.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Concat.\n",
    "X_train = pd.concat([X_train_num, X_train_categ], axis=1)\n",
    "X_test = pd.concat([X_test_num, X_test_categ], axis=1)\n",
    "\n",
    "# Reindex with id_clients\n",
    "X_train[\"SK_ID_CURR\"] = id_clients_train.reset_index(drop=True)\n",
    "X_test[\"SK_ID_CURR\"] = id_clients_test.reset_index(drop=True)\n",
    "\n",
    "df_train = pd.concat([X_train, y_train.reset_index(drop=True)], axis=1)\n",
    "df_test = pd.concat([X_test, y_test.reset_index(drop=True)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export processed data.\n",
    "df_train.to_csv(\"Data/df_train.csv\", index=False)\n",
    "df_test.to_csv(\"Data/df_test.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9329aa1d028b8c46e30aee82431cfeab7c97782acc7187d7a3d576f9c536336f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
