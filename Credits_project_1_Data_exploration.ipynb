{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d632b08c-d252-4238-b496-e2c6edebec4b",
    "_uuid": "eb13bf76d4e1e60d0703856ec391cdc2c5bdf1fb"
   },
   "source": [
    "# PROJET : Implémentation un modèle de scoring (Data Exploration)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour ce projet, nous nous plaçons en tant que **Data Scientist** au sein d'une société financière proposant des crédits à la consommation pour des personnes ayant peu ou pas du tout d'historique de prêt. \n",
    "\n",
    "Notre entreprise souhaite développer un **modèle de scoring de la probabilité de défaut de paiement du client**. Aussi, nous voulons créer un **dashboard interactif** pour que les chargés de relation client puissent expliquer de façon la plus transparente possible les décisions d’octroi de crédit.\n",
    "\n",
    "\n",
    "Ce projet sera constitué de 4 parties distinctes :\n",
    "- Data Exploration (**Stack technique:** `Plotly`)\n",
    "- Data Cleaning & Preprocessing (**Stack technique:** `Sklearn`)\n",
    "- Modelization (**Stack technique:** `Regression Logistique`, `Random Forest`, `LightGBM`, `SMOTE`, `Custom score`)\n",
    "- Dashboarding (**Stack technique:** `Streamlit`, `Plotly`, `Docker`, `Google Cloud Platform`)\n",
    "\n",
    "\n",
    "L'ensemble des fonctions utilisées pour ce projet sont définis dans des fichiers utils.py"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Partie 1 : Data Exploration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce Notebook réalise un preprocessing et une exploration des données.\n",
    "On accorde une importance particulière à la phase de cleaning des données du fait du **déséquilibre des classes** sur les targets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# Classic lib\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# Data viz Lib.\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# File system management.\n",
    "import os\n",
    "\n",
    "# Import custom functions.\n",
    "from Utils.utils_preprocessing import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format & option.\n",
    "sns.set(rc={'figure.figsize':(16,9)})\n",
    "pd.options.display.max_columns = 150\n",
    "\n",
    "# Style use.\n",
    "sns.set_style('darkgrid')\n",
    "sns.set_context(\"notebook\", \n",
    "                font_scale=1.5, \n",
    "                rc={\"lines.linewidth\": 2.5})\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a5e67831-4751-4f11-8e07-527e3e092671",
    "_uuid": "ded520f73b9e94ed47ac2e994a5fb1bcb9093d0f"
   },
   "source": [
    "# Import Data \n",
    "\n",
    "Les données sont composées de **9 fichiers**, un dataset principal d'entrainement (avec les targets), un de test, 7 autres apportant des informations supplémentaires sur les clients.\n",
    "\n",
    "\n",
    "### Dataset dimension :  \n",
    "\n",
    "307511 observations, 122 features  \n",
    "\n",
    "### Features : \n",
    "\n",
    "- Chaque prêt est spécifié par son **SK_ID_CURR**\n",
    "- Chaque prêt à sa **TARGET** (0 : `pas de défaillance` et 1 : `défaillance de paiement`)\n",
    "- **FLAG_OWN_CAR** : possède sa voiture ou non \n",
    "- **AMT_INCOME_TOTAL** : salaire annuel total\n",
    "- **AMT_CREDIT** : montant total du crédit\n",
    "- **DAYS_EMPLOYED** : nbr de jours travaillés\n",
    "- **EXT_SOURCE_1/2/3** : sources extérieures (score entre 0 et 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset import.\n",
    "df_app_train = pd.read_csv('Data/application_train.csv')\n",
    "df_app_train.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Columns Types\n",
    "\n",
    "On regarde le type des features, `int`, `float` ou `object` (variables catégoriques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types.\n",
    "df_app_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of unique value for categorical features.\n",
    "df_app_train.select_dtypes('object').apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check NaN on categorical features\n",
    "df_app_train.select_dtypes('object').isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table on missing values\n",
    "missing_values = missing_values_table(df_app_train)\n",
    "missing_values.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_miss_values(df_app_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "Pour la partie exploration on se focalisera sur les aspects suivant :\n",
    "- Analyse sur le déséquilibre des classes\n",
    "- Repérer des variables scindant bien les populations d'individus postifs et négatifs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Figure 1.\n",
    "fig_tot = make_subplots(rows=1, cols=2,\n",
    "                        specs=[[{\"type\": \"domain\"}, {\"type\": \"bar\"}]],\n",
    "                        subplot_titles=[\"Type of loans\", \"Applicants jobs\"])\n",
    "\n",
    "\n",
    "fig_tot.add_trace(go.Pie(labels=df_app_train[\"NAME_CONTRACT_TYPE\"].value_counts().index, \n",
    "                         values=df_app_train[\"NAME_CONTRACT_TYPE\"].value_counts(), hole=.5, legendgroup = '1'),row=1, col=1)\n",
    "fig_tot.add_trace(go.Bar(x=df_app_train.NAME_EDUCATION_TYPE.dropna().value_counts().index, \n",
    "                         y=df_app_train.NAME_EDUCATION_TYPE.dropna().value_counts(), showlegend=False, marker= dict(color=\"rgb(65, 105, 225)\")), row=1, col=2, )\n",
    "\n",
    "#fig_tot.update_xaxes(tickangle=-90)\n",
    "fig_tot.update_layout(title=\"Applicants informations\", width=950, height=400, \n",
    "                      template=\"plotly_dark\", legend_tracegroupgap=15, xaxis=dict(tickangle=20))\n",
    "fig_tot.show()\n",
    "\n",
    "# Figure 2.\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=df_app_train.OCCUPATION_TYPE.dropna().value_counts().index,\n",
    "                     y=df_app_train.OCCUPATION_TYPE.dropna().value_counts()))\n",
    "fig.update_layout(title=\"Occupation Type\", width=950, height=350, template=\"plotly_dark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify settings of color for exploration.\n",
    "pos_color = 'rgb(225, 127, 0)'\n",
    "neg_color = 'rgb(65, 105, 225)'\n",
    "\n",
    "# Split the initial DF in positive and negative target.\n",
    "df_pos, df_neg  = df_app_train[df_app_train.TARGET == 1], df_app_train[df_app_train.TARGET == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos.AMT_CREDIT = df_pos.AMT_CREDIT.apply(lambda x : np.round(x / 100000, 0) * 100000)\n",
    "df_pos_aggregated = pd.DataFrame(df_pos.groupby(\"AMT_CREDIT\").count().TARGET)\n",
    "\n",
    "df_neg.AMT_CREDIT = df_neg.AMT_CREDIT.apply(lambda x : np.round(x / 100000, 0) * 100000)\n",
    "df_neg_aggregated = pd.DataFrame(df_neg.groupby(\"AMT_CREDIT\").count().TARGET)\n",
    "\n",
    "df_pos_aggregated.TARGET = df_pos_aggregated.TARGET.apply(lambda x : x*100/df_pos_aggregated.TARGET.sum())\n",
    "df_neg_aggregated.TARGET = df_neg_aggregated.TARGET.apply(lambda x : x*100/df_neg_aggregated.TARGET.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count_label = pd.DataFrame(df_app_train.TARGET.value_counts())\n",
    "\n",
    "\n",
    "# Figure 1.\n",
    "fig_tot = make_subplots(rows=1, \n",
    "                        cols=2,\n",
    "                        specs=[[{\"type\": \"bar\"}, {\"type\": \"domain\"}]],\n",
    "                        )\n",
    "\n",
    "fig_tot.add_trace(go.Bar(x = [\"0\"], y = [df_count_label.TARGET[0]], name=\"0\", marker_color=neg_color), row=1, col=1)\n",
    "fig_tot.add_trace(go.Bar(x = [\"1\"], y = [df_count_label.TARGET[1]], name=\"1\", marker_color=pos_color), row=1, col=1)\n",
    "fig_tot.add_trace(go.Pie(labels=df_count_label.index.get_level_values(0), \n",
    "                         values=df_count_label.TARGET, marker=dict(colors=[neg_color, pos_color])),row=1, col=2)\n",
    "\n",
    "fig_tot.update_layout(title=\"Check of imbalanceness\", width=950, height=400, template=\"plotly_dark\", showlegend=False)\n",
    "\n",
    "fig_tot.show()\n",
    "\n",
    "\n",
    "\n",
    "# Figure 2.\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=df_pos_aggregated.index,\n",
    "                     y=list(df_pos_aggregated.TARGET),\n",
    "                     name='1',\n",
    "                     marker_color=pos_color\n",
    "                ))\n",
    "\n",
    "fig.add_trace(go.Bar(x=df_neg_aggregated.index,\n",
    "                     y=list(df_neg_aggregated.TARGET),\n",
    "                     name='0',\n",
    "                     marker_color=neg_color\n",
    "                ))\n",
    "\n",
    "fig.update_layout(xaxis_tickfont_size=14,\n",
    "                  xaxis_range=[0, 1500000],\n",
    "                  yaxis=dict(title='%',\n",
    "                             titlefont_size=16,\n",
    "                             tickfont_size=14),\n",
    "                  xaxis=dict(title='Credit amount'),\n",
    "                  legend=dict(x=0,\n",
    "                              y=1.0,\n",
    "                              bgcolor='rgba(255, 255, 255, 0)',\n",
    "                              bordercolor='rgba(255, 255, 255, 0)'),\n",
    "                  barmode='group',\n",
    "                  bargap=0.15,\n",
    "                  bargroupgap=0.1)\n",
    "\n",
    "fig.update_layout(width=950, height=350, template=\"plotly_dark\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binarize every 5 years.\n",
    "age_data = df_app_train[['TARGET', 'DAYS_BIRTH']]\n",
    "age_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / -365\n",
    "age_data['YEARS_BINNED'] = pd.cut(age_data['YEARS_BIRTH'], bins = np.linspace(20, 70, num = 11))\n",
    "age_data_pos_groups, age_data_neg_groups  = age_data[age_data.TARGET == 1].groupby('YEARS_BINNED').count(), age_data[age_data.TARGET == 0].groupby('YEARS_BINNED').count()\n",
    "\n",
    "age_data_pos_groups[\"interval\"], age_data_neg_groups[\"interval\"] = age_data_pos_groups.index, age_data_neg_groups.index,\n",
    "age_data_pos_groups[\"interval\"] = age_data_pos_groups[\"interval\"].apply(lambda x: str([int(x.left), int(x.right)]))\n",
    "age_data_neg_groups[\"interval\"] = age_data_neg_groups[\"interval\"].apply(lambda x: str([int(x.left), int(x.right)]))\n",
    "\n",
    "age_data_pos_groups[\"TARGET\"] = age_data_pos_groups[\"TARGET\"].apply(lambda x: (x*100)/df_pos.shape[0])\n",
    "age_data_neg_groups[\"TARGET\"] = age_data_neg_groups[\"TARGET\"].apply(lambda x: (x*100)/df_neg.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = make_subplots(rows=1, \n",
    "                    cols=2,\n",
    "                    specs=[[{\"type\": \"xy\"}, {\"type\": \"xy\"}]],\n",
    "                    subplot_titles=['Age distribution', 'Age on positive and negative target'])\n",
    "\n",
    "fig.add_trace(go.Histogram(x=-df_app_train.DAYS_BIRTH/365, nbinsx=75, showlegend=False), row=1, col=1)\n",
    "\n",
    "fig.add_trace(go.Box(x=-df_neg.DAYS_BIRTH / 365, name='0', marker_color=neg_color), row=1, col=2)\n",
    "fig.add_trace(go.Box(x=-df_pos.DAYS_BIRTH / 365, name='1', marker_color=pos_color), row=1, col=2)\n",
    "\n",
    "fig.update_layout(width=950, height=350, template=\"plotly_dark\")\n",
    "fig.show()\n",
    "\n",
    "# Show impact of age on target.\n",
    "fig_tot = go.Figure()\n",
    "\n",
    "fig_tot.add_trace(go.Bar(x=list(age_data_pos_groups.interval), \n",
    "                     y=list(age_data_pos_groups.TARGET),\n",
    "                     name='1',\n",
    "                     marker_color=pos_color))\n",
    "\n",
    "fig_tot.add_trace(go.Bar(x=list(age_data_neg_groups.interval), \n",
    "                     y=list(age_data_neg_groups.TARGET),\n",
    "                     name='0',\n",
    "                     marker_color=neg_color\n",
    "                ))\n",
    "\n",
    "fig_tot.update_layout(xaxis_tickfont_size=14,\n",
    "                  yaxis=dict(title='%',\n",
    "                             titlefont_size=16,\n",
    "                             tickfont_size=14),\n",
    "                  xaxis=dict(title='Groupe of ages'),\n",
    "                  legend=dict(x=0,\n",
    "                              y=1,\n",
    "                              bgcolor='rgba(255, 255, 255, 0)',\n",
    "                              bordercolor='rgba(255, 255, 255, 0)'),\n",
    "                  barmode='group',\n",
    "                  bargap=0.15,\n",
    "                  bargroupgap=0.1)\n",
    "\n",
    "fig_tot.update_layout(width=950, height=350, template=\"plotly_dark\")\n",
    "fig_tot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove an outlier.\n",
    "df_pos = df_pos[df_pos.DAYS_EMPLOYED != 365243]\n",
    "df_neg = df_neg[df_neg.DAYS_EMPLOYED != 365243]\n",
    "\n",
    "fig_1 = go.Figure()\n",
    " \n",
    "fig_1.add_trace(go.Box(x=-df_neg.DAYS_EMPLOYED, name='0', marker_color=neg_color))\n",
    "fig_1.add_trace(go.Box(x=-df_pos.DAYS_EMPLOYED, name='1', marker_color=pos_color))\n",
    "fig_1.update_layout(title=\"Days employed\", width=900, height=300, template=\"plotly_dark\")\n",
    "fig_1.show()\n",
    "\n",
    "\n",
    "fig_tot = make_subplots(rows=1, \n",
    "                        cols=3,\n",
    "                        specs=[[{\"type\": \"xy\"}, {\"type\": \"xy\"}, {\"type\": \"xy\"}]],\n",
    "                        subplot_titles=['External source 1', 'External source 2', 'External source 3'])\n",
    "\n",
    "\n",
    "# Boxplot 1.\n",
    "fig_tot.add_trace(go.Box(y=-df_neg.EXT_SOURCE_1, name='0', marker_color=neg_color), row=1, col=1)\n",
    "fig_tot.add_trace(go.Box(y=-df_pos.EXT_SOURCE_1, name='1', marker_color=pos_color), row=1, col=1)\n",
    "\n",
    "# Boxplot 2.\n",
    "fig_tot.add_trace(go.Box(y=-df_neg.EXT_SOURCE_2, name='0', marker_color=neg_color), row=1, col=2)\n",
    "fig_tot.add_trace(go.Box(y=-df_pos.EXT_SOURCE_2, name='1', marker_color=pos_color), row=1, col=2)\n",
    "\n",
    "# Boxplot 3.\n",
    "fig_tot.add_trace(go.Box(y=-df_neg.EXT_SOURCE_3, name='0', marker_color=neg_color), row=1, col=3)\n",
    "fig_tot.add_trace(go.Box(y=-df_pos.EXT_SOURCE_3, name='1', marker_color=pos_color), row=1, col=3)\n",
    "\n",
    "fig_tot.update_layout(title=\"External sources\", width=900, height=400, template=\"plotly_dark\", showlegend=False)\n",
    "fig_tot.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de corrélation bivariée avec les variables continues\n",
    "\n",
    "- ANOVA Test : \n",
    "\n",
    "H0 : Tous les échantillons ont la même moyenne.  \n",
    "H1 : L'hypothèse alternative est qu'au moins l'un d'eux joue les trouble-fête avec une moyenne sensiblement différente des autres.\n",
    "\n",
    "Le résultat d'ANOVA est la « statistique F ». Ce ratio montre la différence entre la variance à l'intérieur du groupe et la variance entre les groupes, ce qui produit finalement un chiffre qui permet de conclure que l'hypothèse nulle est soutenue ou rejetée. S'il existe une différence significative entre les groupes, l'hypothèse nulle n'est pas soutenue, et le ratio F sera plus grand.\n",
    "\n",
    "La p-valeur est une mesure de référence pour décider du rejet ou non de H0  \n",
    "-> Si p < 0.05 on peut rejetter H0 avec un certain degré de confiance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continuous_cor = check_correlation_classif_task_continuous(df_app_train, 'TARGET')\n",
    "df_continuous_cor.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_continuous_cor.tail(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse de corrélation avec les variables catégoriques\n",
    "\n",
    "- Test du chi-deux -> H0 : les deux variables testées sont indépendantes\n",
    "- Calcul du V de Cramer (Hypothèse : variables catégoriques avec + de 2 modalités)  \n",
    "\n",
    "Plus V est proche de zéro, moins les variables étudiées sont dépendantes. Au contraire, donc, il vaudra 1 lorsque les deux variables sont complètement dépendantes.\n",
    "\n",
    "Conclusion : Il y a une dépendance mais peu significative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_cor = check_correlation_classif_task_categorical(df_app_train, \"TARGET\")\n",
    "df_cat_cor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 08:28:41) \n[Clang 14.0.6 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "9329aa1d028b8c46e30aee82431cfeab7c97782acc7187d7a3d576f9c536336f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
